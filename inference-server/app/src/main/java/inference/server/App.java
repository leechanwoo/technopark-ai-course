/*
 * This Java source file was generated by the Gradle 'init' task.
 */
package inference.server;

import io.grpc.Grpc;
import io.grpc.InsecureServerCredentials;
import io.grpc.Server;
import io.grpc.ServerBuilder;


import ai.onnxruntime.NodeInfo;
import ai.onnxruntime.TensorInfo;
import ai.onnxruntime.OnnxTensor;
import ai.onnxruntime.OnnxTensorLike;
import ai.onnxruntime.OrtEnvironment;
import ai.onnxruntime.OrtException;
import ai.onnxruntime.OrtSession;
import ai.onnxruntime.OrtSession.Result;
import ai.onnxruntime.OrtSession.SessionOptions;
import ai.onnxruntime.OrtSession.SessionOptions.OptLevel;
import ai.onnxruntime.OrtUtil;

import java.io.IOException;
import java.util.Collections;
import java.util.Base64;
import java.util.HashMap;
import java.util.Map;


import com.example.GrpcTest;
import com.example.HelloServiceGrpc;

import com.example.Prediction;
import com.example.PredictionServiceGrpc;
import com.example.Prediction.ImageData;
import com.example.Prediction.CategoricalResult;


public class App {

    public static void main(String[] args) {

        // Server server = ServerBuilder.forPort(50051) // Specify the port to listen on
        Server server = Grpc.newServerBuilderForPort(50051, InsecureServerCredentials.create())
                .addService(new HelloServiceImpl()) // Register your service implementation
                .addService(new PredictionServiceImpl())
                .build();

        try {
            // Start the gRPC server
            server.start();

            System.out.println("Server started and listening on port 50051");

            // Block until the server is shut down
            server.awaitTermination();
        } catch (Exception e) {
            e.printStackTrace();
        }

    }

    static class PredictionServiceImpl extends PredictionServiceGrpc.PredictionServiceImplBase {
        @Override
        public void imagePrediction(
            ImageData image,
            io.grpc.stub.StreamObserver<CategoricalResult> responseObserver) {

                try {
                    float[][] result = onnxRunner(image);

                    // Build and send the response
                    CategoricalResult.Builder builder = CategoricalResult.newBuilder();

                    for (float r: result[0]) {
                        builder.addResult(r);
                    } 
                    CategoricalResult response = builder.build();
                    responseObserver.onNext(response);
                    responseObserver.onCompleted();
                } catch (Exception e) {
                    e.printStackTrace();
                }
        }


        private float[][] onnxRunner(ImageData image) throws OrtException, IOException {
            OrtEnvironment env = OrtEnvironment.getEnvironment();

            OrtSession.SessionOptions opts = new SessionOptions();
            opts.setOptimizationLevel(OptLevel.BASIC_OPT);

            OrtSession pproc_sess = env.createSession("src/main/resources/simple_image_preprocessor.onnx", opts);


            OrtSession model_sess = env.createSession("src/main/resources/mobilenetv2.onnx", opts);

            TensorInfo inputTensorInfo = (TensorInfo) model_sess.getInputInfo().get("input").getInfo();
            long[] shape = inputTensorInfo.getShape();

            String inputName = model_sess.getInputNames().iterator().next();

            // Input data
            int batch = 1;
            int channel = (int)shape[1];
            int row = (int)shape[2];
            int col = (int)shape[3];
            int pcounts = channel*row*col;

            System.out.println(channel);
            System.out.println(row);
            System.out.println(col);


            // byte[] bimg = image.toByteArray();
            byte[] bimg = image.getData().toByteArray();
            float[] fimg = new float[pcounts];

            System.out.println(bimg.length);
            System.out.println(fimg.length);


            for (int i = 0; i < pcounts; i++) {
                fimg[i] = (float)(bimg[i] & 0xFF);
                // fimg[i] /= 255;
            }

            int hImg = image.getHeight();
            int wImg = image.getWidth();
            int cImg = image.getChannel();
            long[] orgShape = { 1, cImg, hImg, wImg };
            long[] inputShape = { 1, channel, row, col };

            OnnxTensor dataTensor = OnnxTensor.createTensor(env, fimg);
            OnnxTensor orgShapeTensor = OnnxTensor.createTensor(env, (Object)orgShape);
            OnnxTensor inputShapeTensor = OnnxTensor.createTensor(env, (Object)inputShape);
            Map<String, OnnxTensor> inputArgs = new HashMap();
            inputArgs.put("RawImg", dataTensor);
            inputArgs.put("shape", orgShapeTensor);
            inputArgs.put("sizes", inputShapeTensor);

            Result pproc_result = pproc_sess.run(inputArgs);
            float[][][][] pproc_img = (float[][][][])pproc_result.get(0).getValue();


            // long[] tshape = { 1, channel, row, col };
            // Object inputImg = OrtUtil.reshape(fimg, tshape);

            // OnnxTensor inputTensor = OnnxTensor.createTensor(env, inputImg);
            OnnxTensor inputTensor = OnnxTensor.createTensor(env, pproc_img);

            Result output = model_sess.run(Collections.singletonMap(inputName, inputTensor));
            return (float[][])output.get(0).getValue();

        }
    }


    static class HelloServiceImpl extends HelloServiceGrpc.HelloServiceImplBase {
        @Override
        public void sayHello(
            GrpcTest.HelloRequest request,
            io.grpc.stub.StreamObserver<GrpcTest.HelloResponse> responseObserver) {
            
            // Implement your server-side logic here
            String message = "Hello, " + request.getName();
            System.out.println(message);

            // Build and send the response
            GrpcTest.HelloResponse response = GrpcTest.HelloResponse
                .newBuilder()
                .setGreeting(message)
                .build();

            responseObserver.onNext(response);
            responseObserver.onCompleted();
        }
    }
}
